![Logo Polytech&INP](logo_Polytech&INP.png)
![Logo PNE](logo_PNE.jpg)
![Logo OFB](logo_OFB.jpg)  
# Benchmark - Nouvelles méthodes de suivi innovantes de la fréquentation <br> Janvier 2024

## Contexte
Ce document est un complément non exhaustif de l’état de l’art réalisé par Aurélien Coste en mai 2023 lors de son stage au Parc National des Écrins. Il s’agit dans ce document, de compléter l’état de l’art de 2023 avec les nouvelles solutions disponibles depuis. L’ancien état de l’art est disponible ici : État de l'art 2023

## Technologies
### Huggingface.co
Huggingface.co est un site qui héberge de nombreux modèles et datasets déposés par une communauté d’utilisateurs. 
Il est possible de faire tourner un modèle via les “spaces” du site, certains sont payants d’autres sont gratuits. 
Il offre également des ressources pour entraîner des modèles. Bien qu’il existe de nombreux modèles et datasets différents, 
le site et ses utilisateurs actifs sont spécialisés dans les modèles de **NLP** (**N**atural **L**anguage **P**rocessing) qui portent essentiellement sur la compréhension, 
la manipulation et la génération du langage naturel par les machines. Exemples : Google translator, Siri, Chatbots, etc

### Kaggle
https://www.kaggle.com/

### CLIP
**CLIP** (**C**onstrastive **L**anguage-**I**mage **P**re-training) est un modèle développé par OpenAI. 
Le modèle combine des capacités de NLP et de vision par ordinateur afin de comprendre les relations entre images et texte. En effet, le modèle est capable de connecter un texte à une image. 
Il peut être appliqué à n’importe quel benchmark de classification visuelle en fournissant simplement les noms des catégories visuelles à reconnaître. 
Néanmoins, CLIP obtient de moins bons résultats dans les tâches un peu plus abstraites ou spécifiques telles que le comptage du nombre d’objets dans une image.
